#LyX 1.5.4 created this file. For more info see http://www.lyx.org/
\lyxformat 276
\begin_document
\begin_header
\textclass article
\language spanish
\inputencoding auto
\font_roman default
\font_sans default
\font_typewriter default
\font_default_family default
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100
\graphics default
\paperfontsize default
\spacing single
\papersize default
\use_geometry false
\use_amsmath 1
\use_esint 0
\cite_engine basic
\use_bibtopic false
\paperorientation portrait
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\defskip medskip
\quotes_language swedish
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\author "" 
\author "" 
\end_header

\begin_body

\begin_layout Section
Computación de alto rendimiento
\end_layout

\begin_layout Standard
Como se mencionó anteriormente, en el correr de los últimos años ha crecido
 la importancia de satisfacer los requisitos crecientes de poder de cómputo
 debido a la necesidad de resolver problemas realistas con modelos más complejos
, así como trabajar con grandes volúmenes de datos sin perder de vista la
 capacidad de respuesta en un tiempo limitado.
 El procesamiento paralelo (o computación paralela de alto rendimiento)
 ha ganado terreno y se ha vuelto muy importante en la resolución de problemas,
 apoyándose en tecnologías como los clusters, supercomputadores y mediante
 el uso de paradigmas de programación paralela y/o distribuida.
\end_layout

\begin_layout Standard
La computación distribuida como modelo para resolver problemas de computación
 masiva utilizando un gran número de computadoras en una infraestructura
 de telecomunicaciones distribuida consiste en compartir recursos heterogéneos
 (basados en distintas plataformas, arquitecturas de computadores y programas,
 lenguajes de programación), situados en distintos lugares y pertenecientes
 a diferentes dominios de administración sobre una red que utiliza estándares
 abiertos.
 La computación distribuida ha sido diseñada para resolver problemas que
 superan la capacidad de cualquier supercomputadora o mainframe, manteniéndose
 la flexibilidad de trabajar en múltiples problemas más pequeños.
 Existen varios grados de distribución: de hardware y procesamiento, de
 datos y de control.
 Algunas de las ventajas de la computación distribuida son la mejora en
 el desempeño, robustez, seguridad no centralizada y acceso transparente
 a los datos no locales.
 Las técnicas de autorización segura son esenciales antes de permitir que
 los recursos informáticos sean controlados por usuarios remotos dado que
 estamos el entorno es generalmente multiusuario.
\end_layout

\begin_layout Standard
La programación paralela es una técnica de programación basada en la ejecución
 simultánea, bien sea en un mismo ordenador (con uno o varios procesadores)
 o en un cluster de ordenadores, en cuyo caso se denomina computación distribuid
a.
 Al contrario que en la programación concurrente, la técnica de paralelización
 enfatiza la verdadera simultaneidad en el tiempo de la ejecución de las
 tareas.
 El avance en diferentes tecnologías como microprocesadores con mayor poder
 de procesamiento, comunicación de datos, desarrollo de bibliotecas e interfaces
 para programación de procesos han posibilitado esta la programación paralela.
 Los multicomputadores y los sistemas con múltiples procesadores consiguen
 un aumento en el rendimiento, mientras que en los sistemas monoprocesador
 el beneficio en rendimiento no es tan evidente, ya que la CPU es compartida
 por múltiples procesos en el tiempo, lo que se denomina multiplexación
 o multiprogramación.
 El mayor problema de la computación paralela radica en la complejidad de
 sincronizar unas tareas con otras, ya sea mediante secciones críticas,
 semáforos o pasaje de mensajes, para garantizar la exclusión mutua en las
 zonas del código en las que sea necesario.
\end_layout

\begin_layout Standard
La programación paralela proporciona ventajas como mayor capacidad de proceso,
 menor tiempo de procesamiento y aprovechamiento de la escalabilidad potencial
 de los recursos.
 Es posible hacer una división de las aplicaciones que requieren una demanda
 de recursos computacionales importantes.
 En primer lugar están las aplicaciones de cálculo intensivas, que requieren
 un alto número de ciclos de máquina y han impulsado el desarrollo de supercompu
tadores.
 Son típicas en ciencias e ingeniería, aunque recientemente han aparecido
 en otras áreas como simulación financiera y económica.
 Algunos ejemplos son aplicaciones para dinámica de fluidos computacional,
 simulaciones electromagnéticas, modelado ambiental, dinámica estructural,
 modelado biológico, dinámica molecular, simulación de redes, modelado financier
o y económico.
\end_layout

\begin_layout Standard
Otro tipo de aplicaciones con una gran demanda de recursos son las de almacenami
ento masivo, dependen de la capacidad para almacenar y procesar grandes
 cantidades de información y requieren de un acceso rápido y seguro a una
 masa considerable de datos almacenados.
 Algunas de ellas son las aplicaciones para análisis de data sísmica, procesamie
nto de imágenes, minería de datos, análisis estadístico de datos y análisis
 de mercados.
\end_layout

\begin_layout Standard
Las aplicaciones exigentes comunicacionalmente son relativamente nuevas
 y pueden ser llamadas servicios por demanda.
 Requieren de recursos computacionales conectados por redes con un ancho
 de banda considerable.
 Por ejemplo procesamiento de transacciones en línea, sistemas colaborativos,
 texto por demanda, vídeo por demanda, imágenes por demanda, simulación
 por demanda.
 Obviamente todas las aplicaciones anteriores dependen en cierto grado de
 cada uno de los aspectos computacionales mencionados: poder de cómputo,
 capacidades de almacenamiento y eficientes canales de comunicación, sin
 embargo las podemos agrupar por su característica dominante.
\end_layout

\begin_layout Standard
Los sistemas de sistemas combinan en forma más compleja las características
 anteriores y dependen, en muchos casos, de sistemas computacionales integrados
 diseñados primordialmente para ellas.
 Ejemplos de sistemas de sistemas son las aplicaciones de soporte a decisiones
 corporativas y gubernamentales, control de sistemas a tiempo real, banca
 electrónica, compras electrónicas, educación.
\end_layout

\begin_layout Standard
Existe una alta correspondencia entre la evolución de tecnologías informáticas
 y el desarrollo de aplicaciones; en particular el hardware tiene gran influenci
a en el éxito de ciertas áreas.
 Las aplicaciones intensivas en cálculo fueron estimuladas principalmente
 por máquinas vectoriales y procesadores masivamente paralelos.
 Las aplicaciones de almacenamiento masivo han sido guiadas por dispositivos
 de almacenamiento como RAID y robots de cintas.
 Las aplicaciones exigentes comunicacionales como herramientas colaborativas
 basadas en WWW y servicios por demanda en línea originalmente surgieron
 con las LAN y están creciendo drásticamente con Internet.
\end_layout

\begin_layout Subsection
Organización de computadores
\end_layout

\begin_layout Standard
La organización de los procesadores se refiere a como se conectan o enlazan
 los procesadores o nodos en un computador paralelo.
 Existen varios criterios para evaluar los distintos diseños de organización.
 Se puede tener en cuenta el diámetro, el cual viene dado por la mayor distancia
 entre dos nodos, mientras menor sea el diámetro menor será el tiempo de
 comunicación entre nodos.
 Otro factor a tener en cuenta es el ancho de bisección de la red, siendo
 este el menor número de enlaces que deben ser removidos para dividir la
 red por la mitad.
 Un ancho de bisección alto puede reducir el tiempo de comunicación cuando
 el movimiento de datos es sustancial, y hace al sistema más tolerante a
 fallas debido a que defectos en un nodo no hacen inoperable a todo el sistema.
\end_layout

\begin_layout Standard
Las redes se pueden separar en redes estáticas y dinámicas, en las redes
 estáticas la topología de interconexión se define cuando se construye.
 Si la red es dinámica, la interconexión puede variar durante la ejecución
 de un programa o entre la ejecución de programas.
\end_layout

\begin_layout Paragraph
Bus y Ethernet (figura 
\begin_inset LatexCommand ref
reference "fig:Bus-y-Ethernet"

\end_inset

).
\end_layout

\begin_layout Standard
En las redes de tipo bus o ethernet los procesadores comparten un único
 bus como recurso de comunicación.
 La arquitectura es fácil y económica de implementar, pero no es escalable
 ya que solo un procesador puede usar el bus en un momento dado, a medida
 que se incrementa el número de procesadores, el bus se convierte en un
 cuello de botella debido a la congestión.
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Standard
\align center
\begin_inset Graphics
	filename Images/bus.png
	width 10cm

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Caption

\begin_layout Standard
\begin_inset LatexCommand label
name "fig:Bus-y-Ethernet"

\end_inset

Bus y Ethernet
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Paragraph
Mallas (figura 
\begin_inset LatexCommand ref
reference "fig:Mallas"

\end_inset

).
\end_layout

\begin_layout Standard
Al igual que la interconexión mediante bus (o ethernet), las mallas son
 fáciles y económicas de implementar, sin embargo el diámetro se incrementa
 al añadir nodos.
 En las mallas de dimensión 1, si los dos nodos extremos también son conectados,
 entonces se tiene un anillo.
 Las mallas de 2 dimensiones y de 3 dimensiones son comunes en computación
 paralela y tiene la ventaja de que pueden ser construidas sin conexiones
 largas.
 El diámetro de las mallas puede ser reducido a la mitad si se extiende
 la malla con conexiones toroidales de forma que los procesadores en los
 bordes también estén conectados con vecinos.
 Esto sin embargo presenta dos desventajas: a) conexiones más largas son
 requeridas y b) un subconjunto de un torus no es un torus y los beneficios
 de esta interconexión se pierden si la máquina es particionada entre varios
 usuarios.
\end_layout

\begin_layout Standard
\align center
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Standard
\align center
\begin_inset Graphics
	filename Images/malla1.png
	width 5cm

\end_inset


\begin_inset Caption

\begin_layout Standard
\begin_inset LatexCommand label
name "fig:Mallas"

\end_inset

Mallas
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Paragraph
Mariposa (figura 
\begin_inset LatexCommand ref
reference "fig:Mariposa"

\end_inset

).
\end_layout

\begin_layout Standard
Las redes de tipo mariposa son similares a las mallas pero presentan menor
 diámetro.
\end_layout

\begin_layout Standard
\align center
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Standard
\align center
\begin_inset Graphics
	filename Images/mariposa.png
	width 5cm
	rotateOrigin center

\end_inset


\begin_inset Caption

\begin_layout Standard
\begin_inset LatexCommand label
name "fig:Mariposa"

\end_inset

Mariposa
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Paragraph
Árboles binarios.
\end_layout

\begin_layout Standard
Los árboles binarios son particularmente útiles en problemas de ordenamiento,
 multiplicación de matrices, y algunos problemas en los que los tiempos
 de solución crecen exponencialmente con el tamaño del problema (NP-difíciles).
 
\end_layout

\begin_layout Paragraph
Pirámides (figura 
\begin_inset LatexCommand ref
reference "fig:Pirámides"

\end_inset

).
\end_layout

\begin_layout Standard
Las redes de tipo pirámide intentan combinar las ventajas de las mallas
 y los árboles, se incrementa la tolerancia a fallas y el número de vías
 de comunicación.
\end_layout

\begin_layout Standard
\align center
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Standard
\align center
\begin_inset Graphics
	filename Images/piramide.png
	height 5cm

\end_inset


\begin_inset Caption

\begin_layout Standard
\begin_inset LatexCommand label
name "fig:Pirámides"

\end_inset

Pirámides
\end_layout

\end_inset


\end_layout

\begin_layout Standard

\end_layout

\end_inset


\end_layout

\begin_layout Paragraph
Hipercubo (figura 
\begin_inset LatexCommand ref
reference "fig:Hipercubo"

\end_inset

).
\end_layout

\begin_layout Standard
Un hipercubo puede ser considerado como una malla con conexiones largas
 adicionales, estas conexiones reducen el diámetro e incrementan el ancho
 de bisección.
 
\end_layout

\begin_layout Standard
Se puede definir recursivamente un hipercubo de la siguiente manera: un
 hipercubo de dimensión-cero es un único procesador y un hipercubo de dimensión-
uno conecta dos hipercubos de dimensión-cero.
 En general, un hipercubo de dimensión d+1 con 2d+1 nodos se construye conectand
o los procesadores respectivos de dos hipercubos de dimensión d.
 
\end_layout

\begin_layout Standard
\align center
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Standard
\align center
\begin_inset Graphics
	filename Images/hipercubos.png
	width 10cm

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Caption

\begin_layout Standard
\begin_inset LatexCommand label
name "fig:Hipercubo"

\end_inset

Hipercubo
\end_layout

\end_inset


\end_layout

\begin_layout Standard

\end_layout

\end_inset


\end_layout

\begin_layout Paragraph
Omega.
\end_layout

\begin_layout Standard
Omega es una red formada por crossbar switches 2x2, con cuatro estados posibles:
 recto, cruzado, broadcast superior y broadcast inferior que son configurados
 según la conexión que se tiene.
 Estas topologías se llaman dinámicas o reconfigurables.
 
\end_layout

\begin_layout Standard
Estas redes reducen considerablemente la competencia por ancho de banda,
 pero son altamente no escalables y costosas.
 El switch de alto desempeño de la SP2 es una red omega.
\end_layout

\begin_layout Standard
La figura 
\begin_inset LatexCommand ref
reference "fig:Omega"

\end_inset

 muestra una red omega de 3 etapas que conecta 8 procesadores.
\end_layout

\begin_layout Standard
\align center
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Standard
\align center
\begin_inset Graphics
	filename Images/omega3e8p.png
	width 8cm

\end_inset


\begin_inset Caption

\begin_layout Standard
\begin_inset LatexCommand label
name "fig:Omega"

\end_inset

Omega
\end_layout

\end_inset


\end_layout

\begin_layout Standard

\end_layout

\end_inset


\end_layout

\begin_layout Paragraph
Fibras de interconexión (figura 
\begin_inset LatexCommand ref
reference "fig:Fibras-de-interconexión"

\end_inset

).
\end_layout

\begin_layout Standard
Las fibras de interconexión son un conjunto de switches, llamados routers,
 enlazados por distintas configuraciones o topologías.
\end_layout

\begin_layout Standard
\align center
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Standard
\align center
\begin_inset Graphics
	filename Images/firasinterconexion.png
	width 8cm

\end_inset


\begin_inset Caption

\begin_layout Standard
\begin_inset LatexCommand label
name "fig:Fibras-de-interconexión"

\end_inset

Fibras de interconexión
\end_layout

\end_inset


\end_layout

\begin_layout Standard

\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Diseño de algoritmos paralelos
\end_layout

\begin_layout Standard
El diseño de algoritmos paralelos involucra cuatro etapas, las cuales se
 presentan como secuenciales pero que en la práctica no lo son.
\end_layout

\begin_layout Standard
La primer etapa es la de partición, en esta etapa el cómputo y los datos
 sobre los cuales se opera se descomponen en tareas.
 En este punto del diseño se ignoran aspectos como el número de procesadores
 de la máquina a usar y se concentra la atención en explotar oportunidades
 de paralelismo.
\end_layout

\begin_layout Standard
Finalizada la primer etapa, se inicia la etapa de comunicación donde se
 determina la comunicación para coordinar las tareas, se definen estructuras
 y algoritmos de comunicación.
\end_layout

\begin_layout Standard
Luego en la etapa de agrupación se evalúa en términos de eficiencia y costos
 de implementación a las dos etapas anteriores.
 Se agrupan tareas pequeñas en tareas más grandes.
\end_layout

\begin_layout Standard
En la última etapa cada tarea es asignada a un procesador tratando de maximizar
 la utilización de los procesadores y de reducir el costo de comunicación.
 La asignación puede ser estática (se establece antes de la ejecución del
 programa) o en tiempo de ejecución mediante algoritmos de balanceo de carga.
\end_layout

\begin_layout Subsubsection
Partición.
\end_layout

\begin_layout Standard
En la etapa de partición se buscan oportunidades de paralelismo y se trata
 de subdividir el problema lo más finamente posible, dividiendo tanto los
 cómputos como los datos.
 
\end_layout

\begin_layout Standard
Existen dos formas de descomposición, descomposición del dominio y descomposició
n funcional.
 La descomposición del dominio se centra en los datos, se determina la partición
 apropiada de los datos y luego se trabaja en los cómputos asociados con
 los datos.
 La descomposición funcional es el contrario al enfoque anterior, primero
 se descomponen los cómputos y luego se ocupa de los datos.
 
\end_layout

\begin_layout Standard
En el proceso de partición existen varios aspectos a tener en cuenta, en
 particular el orden de tareas debe ser por lo menos superior al número
 de procesadores para tener flexibilidad en etapas siguientes.
 Es importante evitar cómputos y almacenamientos redundantes, y las tareas
 deben ser de tamaños equivalentes para facilitar el balanceo de la carga
 de los procesadores.
 Para permitir cierta escalabilidad el número de tareas debe ser proporcional
 al tamaño del problema.
\end_layout

\begin_layout Subsubsection
Comunicación
\end_layout

\begin_layout Standard
El proceso de partición de tareas no es independiente del proceso de comunicació
n.
 En el proceso de comunicación se especifica como los datos serán transferidos
 o compartidos entre tareas.
\end_layout

\begin_layout Standard
La comunicación puede ser definida en dos fases.
 Primero se definen los canales que conectan las tareas y luego se especifica
 la información o mensajes que deben ser enviados y recibidos en estos canales.
\end_layout

\begin_layout Standard
La forma de organización de la memoria (distribuida o compartida) determinará
 la forma de atacar la comunicación entre tareas.
 En ambientes de memoria distribuida, las tareas tienen una identificación
 única e interactúan enviando y recibiendo mensajes hacia y desde tareas
 específicas.
 Las bibliotecas más conocidas para implementar el pasaje de mensajes en
 ambientes de memoria distribuida son MPI (Message Passing Interface) y
 PVM (Parallel Virtual Machine).
\end_layout

\begin_layout Standard
En ambientes de memoria compartida no existe la noción de pertenencia y
 el envío de datos no se da como tal.
 Todas las tareas comparten la misma memoria.
 Semáforos, semáforos binarios, barreras y otros mecanismos de sincronización
 son usados para controlar el acceso a la memoria compartida y coordinar
 las tareas.
\end_layout

\begin_layout Standard
Para poder dar esta etapa por terminada es necesario tener en cuenta varios
 aspectos.
 Cada tarea debe efectuar aproximadamente el mismo número de operaciones
 de comunicación que cada una de las demás tareas.
 De otra forma es muy probable que el algoritmo no sea extensible a problemas
 mayores ya que habrán cuellos de botella.
 La comunicación entre tareas debe ser tan reducida como sea posible, de
 esta forma los procesos no se trancan entre sí en la espera de mensajes
 y se evita que el canal de comunicación sea un cuello de botella.
 Las operaciones de comunicación y los cómputos de diferentes tareas deben
 poder proceder concurrentemente.
\end_layout

\begin_layout Subsubsection
Agrupación
\end_layout

\begin_layout Standard
Durante las tareas de participación y comunicación el algoritmo resultante
 es aún abstracto en el sentido de que no se tomó en cuenta la arquitectura
 sobre la que se ejecutará.
 En este proceso se busca un algoritmo concreto, que se ejecute eficientemente
 sobre cierta clase de computadores.
 En particular, se considera la utilidad de agrupar tareas y de replicar
 datos y/o cómputos.
\end_layout

\begin_layout Standard
En el proceso de partición se trata de establecer el mayor número posible
 de tareas con la intención de maximizar el paralelismo.
 La maximización de tareas no necesariamente produce un algoritmo eficiente,
 ya que el costo de comunicación puede ser significativo.
 
\end_layout

\begin_layout Standard
Mediante la agrupación de tareas se puede reducir la cantidad de datos a
 enviar y así reducir el número de mensajes y el costo de comunicación.
 Se puede intentar replicar cómputos y/o datos para reducir los requerimientos
 de comunicación.
 
\end_layout

\begin_layout Standard
En esta etapa es importante chequear si la agrupación redujo los costos
 de comunicación.
 A su vez si se han replicado cómputos y/o datos, se debe verificar que
 los beneficios son superiores a los costos.
 Se debe verificar que las tareas resultantes tengan costos de cómputo y
 comunicación similares.
 
\end_layout

\begin_layout Standard
Al igual que en las otras etapas se debe revisar si el número de tareas
 es extensible con el tamaño del problema.
 Si el agrupamiento ha reducido las oportunidades de ejecución concurrente,
 se debe verificar que aun hay suficiente concurrencia y posiblemente considerar
 diseños alternativos.
\end_layout

\begin_layout Standard
Finalmente se deberá analizar si es posible reducir aun más el número de
 tareas sin desbalancear la carga o reducir la extensibilidad.
\end_layout

\begin_layout Subsubsection
Asignación
\end_layout

\begin_layout Standard
En este proceso se determina en que procesador se ejecutará cada tarea.
 En máquinas de memoria compartida tipo UMA no se presenta este problema
 ya que proveen asignación dinámica de procesos.
 
\end_layout

\begin_layout Standard
Actualmente no hay mecanismos generales de asignación de tareas para máquinas
 distribuidas por lo que este problema debe ser atacado explícitamente en
 el diseño de algoritmos paralelos.
\end_layout

\begin_layout Standard
La asignación de tareas puede ser estática o dinámica.
 En la asignación estática, las tareas son asignadas a un procesador al
 comienzo de la ejecución del algoritmo paralelo y corren ahí hasta el final.
 La asignación estática en ciertos casos puede resultar en un tiempo de
 ejecución menor respecto a asignaciones dinámicas y también puede reducir
 el costo de creación de procesos, sincronización y terminación.
\end_layout

\begin_layout Standard
En la asignación dinámica se hacen cambios en la distribución de las tareas
 entre los procesadores en tiempo de ejecución, con el fin de balancear
 la carga del sistema y reducir el tiempo de ejecución.
 Sin embargo, el costo de realizar el balance puede ser significativo y
 por ende incrementar el tiempo de ejecución.
 
\end_layout

\begin_layout Standard
Los algoritmos de balanceo de carga se pueden clasificar como balanceo centraliz
ado, balanceo completamente distribuido y balanceo semi-distribuido.
 Cuando el balanceo es centralizado un nodo ejecuta el algoritmo y mantiene
 el estado global del sistema.
 Como contrapartida cuando el balanceo es completamente distribuido cada
 procesador mantiene su propia visión del sistema intercambiando información
 con sus vecinos y así hacer cambios locales.
\end_layout

\begin_layout Standard
Como posible punto intermedio entre ambos tipos de algoritmo está el balanceo
 semi-distribuido, donde los procesadores se dividen en regiones, cada una
 con un algoritmo centralizado local mientras que otro algoritmo balancea
 la carga entre las regiones.
\end_layout

\begin_layout Subsection
Taxonomía de Flynn.
\end_layout

\begin_layout Standard
Una forma de clasificar las diferentes arquitecturas de computación secuenciales
 y paralelas, es mediante la taxonomía de Flynn, que está basada en la multiplic
idad del flujo de instrucciones y del flujo de datos en un computador.
 Un flujo de instrucciones es una secuencia de instrucciones ejecutadas
 por el computador y un flujo de datos es la secuencia de datos sobre los
 cuales operan las instrucciones.
\end_layout

\begin_layout Standard
Dentro de la clasificación de Flynn hay varias categorías.
 La primera de ellas es SISD, Single Instruction stream, Single Data stream
 (ver figura 
\begin_inset LatexCommand ref
reference "SISD"

\end_inset

).
 La mayor parte de computadores seriales son SISD, teniendo en general un
 CPU que ejecuta una instrucción y busca o guarda datos en un momento dado.
\end_layout

\begin_layout Standard
\align center
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Standard
\align center
\begin_inset Graphics
	filename Images/SISD.png
	width 5cm

\end_inset


\end_layout

\begin_layout List
\labelwidthstring 00.00.0000
\align left
UP: Unidad de Procesamiento
\end_layout

\begin_layout List
\labelwidthstring 00.00.0000
UC: Unidad de Control 
\end_layout

\begin_layout List
\labelwidthstring 00.00.0000
M: Memoria 
\end_layout

\begin_layout List
\labelwidthstring 00.00.0000
FI: Flujo de Instrucciones 
\end_layout

\begin_layout List
\labelwidthstring 00.00.0000
FD: Flujo de Datos
\end_layout

\begin_layout Standard
\align center
\begin_inset Caption

\begin_layout Standard
\begin_inset LatexCommand label
name "SISD"

\end_inset

Single Instruction stream, Single Data stream
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
La segunda categoría es SIMD, Single Instruction stream, Multiple Data stream
 (ver figura 
\begin_inset LatexCommand ref
reference "SIMD"

\end_inset

).
 Esta categoría comprende los arreglos de procesadores.
 Tiene un conjunto de unidades de procesamiento cada una ejecutando la misma
 operación sobre datos distintos.
\end_layout

\begin_layout Standard
\align center
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Standard
\align center
\begin_inset Graphics
	filename Images/SIMD.png
	width 6cm

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Caption

\begin_layout Standard
\begin_inset LatexCommand label
name "SIMD"

\end_inset

Single Instruction stream, Multiple Data stream
\end_layout

\end_inset


\end_layout

\begin_layout Standard

\end_layout

\end_inset


\end_layout

\begin_layout Standard
En la categoría MISD, Multiple Instruction stream, Single Data stream (ver
 figura 
\begin_inset LatexCommand ref
reference "MISD"

\end_inset

) existen n procesadores, cada uno recibiendo una instrucción diferente
 y operando sobre el mismo flujo de datos.
 Actualmente no hay máquinas de este tipo por ser poco prácticas, a pesar
 de que ciertas MIMD puedan ser usadas de esta forma.
\end_layout

\begin_layout Standard
\align center
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Standard
\align center
\begin_inset Graphics
	filename Images/MISD.png
	width 6cm

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Caption

\begin_layout Standard
\begin_inset LatexCommand label
name "MISD"

\end_inset

Multiple Instruction stream, Single Data stream
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
La categoría de MIMD, Multiple Instruction stream, Multiple Data stream
 (ver figura 
\begin_inset LatexCommand ref
reference "MIMD"

\end_inset

) incluye a la mayoría de los multiprocesadores y multicomputadores, que
 en general tienen más de un procesador independiente, y cada uno puede
 ejecutar un programa diferente sobre sus propios datos.
 Es posible hacer una segunda categorización según su forma de organización
 de memoria, ya sea memoria compartida o memoria distribuida.
\end_layout

\begin_layout Standard
\align center
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Standard
\align center
\begin_inset Graphics
	filename Images/MIMD.png
	width 6cm

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Caption

\begin_layout Standard
\begin_inset LatexCommand label
name "MIMD"

\end_inset

Multiple Instruction stream, Multiple Data stream
\end_layout

\end_inset


\end_layout

\begin_layout Standard

\end_layout

\end_inset


\end_layout

\begin_layout Standard
Por último la categoría SPMD (Single Program, Multiple Data), donde cada
 procesador ejecuta una copia exacta del mismo programa, pero opera sobre
 datos diferentes.
 Pese a no ser una categoría definida por Flynn es muy usada y puede ser
 considerada como un caso particular de MIMD.
\end_layout

\begin_layout Subsection
Arquitecturas de computación paralela
\end_layout

\begin_layout Standard
En esta sección se enumeran las diferentes arquitecturas que se peuden encontrar
 relacionadas a la computación paralela.
\end_layout

\begin_layout Subsubsection
Arreglos de procesadores
\end_layout

\begin_layout Standard
En un arreglo de procesadores tenemos un computador cuyo conjunto de instruccion
es permite operaciones tanto sobre vectores como escalares al que se denomina
 computador vectorial.
\end_layout

\begin_layout Paragraph
Procesador Vectorial Pipelined.
\end_layout

\begin_layout Standard
En estas máquinas los vectores fluyen a través de las unidades aritméticas
 pipelined.
 Las unidades consisten de una cascada de etapas de procesamiento compuestas
 de circuitos que efectúan operaciones aritméticas o lógicas sobre el flujo
 de datos que pasan a través de ellas.
\end_layout

\begin_layout Standard
Las etapas están separadas por registros de alta velocidad usados para guardar
 resultados intermedios.
 La información que fluye entre las etapas adyacentes esta bajo el control
 de un reloj R que se aplica a todos los registros simultáneamente.
 En esta categoría tenemos máquinas como la Cray-1 y la Cyber-205.
\end_layout

\begin_layout Paragraph
Arreglos de Procesadores.
\end_layout

\begin_layout Standard
Son máquinas que constan de un computador secuencial conectado a un arreglo
 de elementos de procesamiento sincronizados e idénticos capaces de ejecutar
 las mismas operaciones sobre datos diferentes.
 El computador secuencial generalmente es un CPU de propósito general que
 almacena el programa y los datos que serán operados en paralelo, además
 de ejecutar la porción del programa que es secuencial.
 Los elementos de procesamiento se asemejan a CPUs pero no tienen unidades
 de control propias; el computador secuencial genera todas las señales de
 control para las unidades de procesamiento en el computador.
\end_layout

\begin_layout Standard
Los arreglos de procesamiento difieren fundamentalmente en la complejidad
 y la topología de interconexión de sus elementos de procesamiento.
 Ejemplos de estas máquinas son: IILIAC IV, Goodyear MPP y Connection Machine
 CM-200.
\end_layout

\begin_layout Subsubsection
Multiprocesadores
\end_layout

\begin_layout Standard
Son equipos formados por un número de procesadores completamente programables
 capaces de ejecutar su propio programa.
\end_layout

\begin_layout Standard
La principal debilidad que presentan los multiprocesadores (máquinas de
 memoria compartida) radica en que no se pueden agregar procesadores indefinidam
ente ya que a partir de cierto número y dependiendo de la aplicación, el
 mecanismo de switches o enrutamiento se satura, generando un problema important
e a la hora de escalar la solución.
\end_layout

\begin_layout Paragraph
UMA: Multiprocesadores de Acceso Uniforme a Memoria.
\end_layout

\begin_layout Standard
Estos computadores tienen sus procesadores interconectados a través de un
 mecanismo de switches a una memoria compartida centralizada.
 Entre estos mecanismos están: un bus común, crossbar switches o packet-switched
 networks.
\end_layout

\begin_layout Standard
Encore Multimax y Sequent Symetry S81 son ejemplos comerciales de este tipo
 de multiprocesadores.
\end_layout

\begin_layout Paragraph
NUMA: Multiprocesadores de Acceso No-Uniforme a Memoria.
\end_layout

\begin_layout Standard
Estos multiprocesadores tienen el espacio de direccionamiento compartido
 y la memoria distribuida.
 La memoria compartida está formada por la memoria local de los procesadores.
 El tiempo de acceso a memoria depende de si el acceso es local al procesador
 o no.
 La BBN TC2000 y la SGI Origin 2000 son ejemplos de este modelo de computación
 paralela.
\end_layout

\begin_layout Subsubsection
Multicomputadores
\end_layout

\begin_layout Standard
Una de las principales características de los multicomputadores es que los
 procesadores que los conforman no comparten memoria, cada procesador tiene
 su propia memoria privada (máquinas de memoria distribuida) y la interacción
 entre ellos es a través de pasaje de mensajes.
 Ejemplos son: Intel ParagonXP/S, Meikos Computing Surface, nCUBE 2, Parsytec
 SuperCluster, Thinking Machine CM-5 y la IBM SP2.
\end_layout

\begin_layout Subsubsection
Máquinas de memoria compartida distribuida
\end_layout

\begin_layout Standard
Actualmente las máquinas paralelas tienden a aprovechar las facilidades
 de programación que ofrecen los ambientes de memoria compartida y la escalabili
dad de los ambientes de memoria distribuida.
 Este modelo conecta entre sí módulos de multiprocesadores manteniendo la
 visión global de la memoria.
 
\end_layout

\begin_layout Standard
Las máquinas de memoria compartida distribuida entra dentro de la categoría
 de NUMA y un ejemplo es la SGI Origin 2000.
\end_layout

\begin_layout Subsubsection
Multiprocesadores multi-hebrados
\end_layout

\begin_layout Standard
En los multiprocesadores multi-hebrados, cada procesador tiene cierto número
 de flujos de instrucciones implementados en hardware, incluyendo el contador
 de programa y registros, cada uno destinado a ejecutar una hebra.
 En cada ciclo el procesador ejecuta instrucciones de una de las hebras.
 En el ciclo siguiente, el procesador hace un cambio de contexto y ejecuta
 instrucciones de otra hebra.
\end_layout

\begin_layout Standard
La Tera MTA (multithreaded architecture) es el primer ejemplo con esta arquitect
ura, donde cada procesador tiene 128 flujos de instrucciones.
 Un acceso a memoria dura aproximadamente 100 ciclos por lo que en la próxima
 ejecución de la hebra se tendrán los datos requeridos.
 Este mecanismo permite a la MTA tolerar la latencia a memoria y por lo
 tanto no requiere de memorias cache.
\end_layout

\begin_layout Standard
Cada instrucción de 64-bits codifica 3 operaciones (una de memoria y dos
 que pueden ser aritméticas o de control).
 Cuenta con un sistema operativo de versión distribuida completamente simétrica
 de UNIX.
\end_layout

\begin_layout Standard
El sistema cuenta con entre 1 y 256 procesadores que comparten una enorme
 memoria.
 A su vez cada procesador tiene 1 o 2 GB de memoria, un mapeo aleatorio
 de la memoria y una red altamente interconectada proveen acceso casi uniforme
 de cualquier procesador a cualquier memoria.
\end_layout

\begin_layout Standard
Los estudios realizados muestran que el costo del multi-hebrado es pequeño,
 con un rendimiento comparable con el de la T90 y los códigos de la MTA
 son significativamente más fáciles de optimizar que en máquinas masivamente
 paralelas o estaciones de trabajo de alto rendimiento.
\end_layout

\begin_layout Subsubsection
Cluster de PC's
\end_layout

\begin_layout Standard
El término cluster se aplica a los conjuntos de computadoras unidos mediante
 una red de alta velocidad que se comportan como si fuesen un único recurso
 computacional con mayor poder de cómputo.
 Hoy en día los clusters de PC's tienen un papel importante en aplicaciones
 científicas, de ingeniería, comerciales, simulaciones, etc.
\end_layout

\begin_layout Standard
La tecnología de clusters ha evolucionado apoyándose en actividades que
 van desde aplicaciones de supercómputo y software de misiones críticas,
 servidores Web y comercio electrónico, hasta bases de datos de alto rendimiento.
\end_layout

\begin_layout Standard
El uso de clusters surge gracias a la convergencia de varias tendencias
 actuales como la disponibilidad de microprocesadores económicos de alto
 rendimiento y redes de alta velocidad, la existencia de herramientas para
 cómputo distribuido de alto rendimiento, así como la creciente necesidad
 de potencia computacional para aplicaciones que la requieran.
\end_layout

\begin_layout Standard
Se espera de un cluster que presente combinaciones de las siguientes característ
icas: alto rendimiento, alta disponibilidad, equilibrio de carga y escalabilidad.
 
\end_layout

\begin_layout Standard
La construcción de los cluster es económica debido a su flexibilidad, permitiend
o tener varios computadores con la misma configuración de hardware y sistema
 operativo (cluster homogéneo), diferente rendimiento pero con arquitecturas
 y sistemas operativos similares (cluster semi-homogéneo), o tener diferente
 hardware y sistema operativo (cluster heterogéneo).
\end_layout

\begin_layout Standard
Se pueden construir clusters con ordenadores personales desechados por anticuado
s que consiguen competir en capacidad de cálculo con superordenadores de
 precios elevados.
\end_layout

\begin_layout Paragraph
Cluster de alto rendimiento.
\end_layout

\begin_layout Standard
Un cluster de alto rendimiento está diseñado para dar altas prestaciones
 de capacidad de cálculo.
\end_layout

\begin_layout Standard
Por medio de un cluster se pueden conseguir capacidades de cálculo superiores
 a las de un ordenador más caro.
 Para garantizar esta capacidad de cálculo, los problemas necesitan ser
 paralelizables, ya que el método con el que los clusters agilizan el procesamie
nto es dividir el problema en subproblemas más pequeños y resolverlos en
 los nodos.
\end_layout

\begin_layout Paragraph
Cluster de alta disponibilidad.
\end_layout

\begin_layout Standard
Un cluster de alta disponibilidad se caracteriza por compartir los discos
 de almacenamiento de datos, los distintos computadores se monitorean constantem
ente entre sí para responder en forma instantánea frente a la caída de uno
 de ellos..
 
\end_layout

\begin_layout Standard
Los clusters de alta disponibilidad pueden dividirse entre clusters de alta
 disponibilidad de infraestructura y clusters de alta disponibilidad de
 aplicación.
\end_layout

\begin_layout Paragraph
Cluster de balanceo de carga.
\end_layout

\begin_layout Standard
Un cluster de equilibrio de carga o de cómputo adaptativo está compuesto
 por uno o más ordenadores que actúan como front-end del cluster, y que
 se ocupan de repartir las peticiones de servicio que reciba el cluster
 a otros ordenadores del cluster que forman el back-end de éste.
\end_layout

\begin_layout Paragraph
Escalabilidad.
\end_layout

\begin_layout Standard
La escalabilidad es la propiedad deseable de un sistema, una red o un proceso,
 que indica su habilidad para, o bien manejar el crecimiento continuo de
 trabajo de manera fluida, o bien para estar preparado para crecer en tamaño
 sin perder calidad en los servicios ofrecidos.
 La capacidad de este tipo de clusters se puede ampliar fácilmente añadiendo
 más ordenadores al cluster.
\end_layout

\begin_layout Standard
La robustez es una de las características más importantes ya que ante la
 caída de alguno de los ordenadores del cluster el servicio se puede ver
 mermado, pero mientras haya ordenadores en funcionamiento, éstos seguirán
 dando servicio.
\end_layout

\begin_layout Subsection
Herramientas para la programación paralela
\end_layout

\begin_layout Standard
En programación paralela existen diferentes lenguajes y herramientas de
 programación con características específicas para diferentes clases de
 problema.
 A continuación veremos algunas de estas herramientas.
\end_layout

\begin_layout Standard
C++ Composicional es una extensión de C++ que provee al programador facilidades
 para controlar localidad, concurrencia, comunicaciones, y asignación de
 tareas.
 Puede ser usado para construir librerías que implementen tareas, canales,
 y otras abstracciones básicas de la programación paralela.
\end_layout

\begin_layout Standard
High Performance Fortran (HPF) es un ejemplo de lenguajes datos-paralelos
 y se ha convertido en un estándar para aplicaciones científicas e ingenieriles.
 El paralelismo es expresado en términos de operaciones sobre matrices y
 la comunicación es inferida por el compilador.
\end_layout

\begin_layout Standard
Parallel Virtual Machine (PVM) es una biblioteca de subrutinas para enviar
 y recibir mensajes.
\end_layout

\begin_layout Standard
Message Passing Interface (MPI) es una biblioteca similar a PVM pero, tal
 como HPF, MPI se ha convertido un estándar.
\end_layout

\begin_layout Subsubsection
MPI: Message Passing Interface
\end_layout

\begin_layout Standard
MPI es un estándar que define la sintaxis y la semántica de las funciones
 contenidas en una librería de paso de mensajes diseñada para ser usada
 en programas que exploten la existencia de múltiples procesadores.
 Fue creado por científicos desarrolladores de software y aplicaciones bajo
 el objetivo de desarrollar un estándar portable y eficiente para programación
 paralela.
 Implementaciones del estandar en forma de biblioteca permiten trabajar
 con memoria distribuida, tener paralelismo explícito y contener un único
 mecanismo de comunicación que puede ser punto a punto.
 
\end_layout

\begin_layout Standard
El número de tareas es fijado en tiempo de pre-ejecución (aunque esto ha
 cambiado en la versión 2 del estándar) y permite agrupamiento de procesos
 e incluye contextos de comunicación entre grupos de procesos.
\end_layout

\begin_layout Standard
La característica que hace que las implementaciones de este estandar sea
 de especial interes para sistemas distribuidos es que no utiliza memorai
 compartida.
\end_layout

\begin_layout Standard
Los elementos principales que intervienen en el paso de mensajes son el
 proceso que envía, el que recibe y el mensaje.
 Dependiendo de si el proceso que envía el mensaje espera a que el mensaje
 sea recibido, se puede hablar de paso de mensajes síncrono o asíncrono.
 En el paso de mensajes asíncrono, el proceso que envía, no espera a que
 el mensaje sea recibido, y continúa su ejecución, siendo posible que vuelva
 a generar un nuevo mensaje y a enviarlo antes de que se haya recibido el
 anterior.
 Por este motivo se suelen emplear buzones, en los que se almacenan los
 mensajes a espera de que un proceso los reciba.
 Generalmente empleando este sistema, el proceso que envía mensajes solo
 se bloquea o para, cuando finaliza su ejecución, o si el buzón está lleno.
 En el paso de mensajes síncrono, el proceso que envía el mensaje espera
 a que un proceso lo reciba para continuar su ejecución.
 Por esto se suele llamar a esta técnica encuentro, o rendezvous.
 Dentro del paso de mensajes síncrono se engloba a la llamada a procedimiento
 remoto, muy popular en las arquitecturas cliente/servidor.
 La Interfaz de Paso de Mensajes es un protocolo de comunicación entre computado
ras, es el estándar para la comunicación entre los nodos que ejecutan un
 programa en un sistema de memoria distribuida.
 
\end_layout

\begin_layout Standard
Las implementaciones en MPI consisten en un conjunto de bibliotecas de rutinas
 que pueden ser utilizadas en programas escritos en los lenguajes de programació
n C, C++, Fortran y Ada.
 La ventaja de MPI sobre otras bibliotecas de paso de mensajes, es que los
 programas que utilizan la biblioteca son portables (dado que MPI ha sido
 implementado para casi toda arquitectura de memoria distribuida), y rápidos,
 (porque cada implementación de la librería ha sido optimizada para el hardware
 en la cual se ejecuta).
\end_layout

\begin_layout Subsubsection
PVM: Parallel Virtual Machine
\end_layout

\begin_layout Standard
Es una biblioteca para el desarrollo de aplicaciones paralelas y distribuidas.
 PVM surge como proyecto de laboratorio universitario y fue adoptado como
 estándar de facto, aunque no es estándar de la industria.
\end_layout

\begin_layout Standard
Algunas de sus cualidades son potencia, simplicidad, portabilidad, practicidad.
\end_layout

\begin_layout Standard
Permite la administración dinámica de un conjunto de equipos que conforman
 la máquina virtual.
 Contiene mecanismos de creación e identificación de procesos, un modelo
 de comunicación entre procesos basado en pasaje de mensajes y brinda mecanismos
 de sincronización de procesos.
\end_layout

\begin_layout Standard
Brinda soporte para manejar heterogeneidad y aprovecha las arquitecturas
 multiprocesador.
\end_layout

\begin_layout Subsubsection
Middleware
\end_layout

\begin_layout Standard
El Middleware es un software de conectividad que ofrece un conjunto de servicios
 que hacen posible el funcionamiento de aplicaciones distribuidas sobre
 plataformas heterogéneas.
 Funciona como una capa de abstracción de software distribuida, que se sitúa
 entre las capas de aplicaciones y las capas inferiores (sistema operativo
 y red).
 El Middleware nos abstrae de la complejidad y heterogeneidad de las redes
 de comunicaciones subyacentes, así como de los sistemas operativos y lenguajes
 de programación, proporcionando una API para la fácil programación y manejo
 de aplicaciones distribuidas, dando a su vez la sensación al usuario de
 que utiliza un único computador muy potente.
 Dependiendo del problema a resolver y de las funciones necesarias, serán
 útiles diferentes tipo de servicios de middleware.
\end_layout

\begin_layout Standard
Por lo general el middleware del lado cliente está implementado por el Sistema
 Operativo subyacente, el cual posee las librerías que implementan todas
 las funcionalidades para la comunicación a través de la red.
\end_layout

\begin_layout Standard
Además ofrece herramientas para la optimización y mantenimiento del sistema:
 migración de procesos, checkpoint-restart (congelar uno o varios procesos,
 mudarlos de servidor y continuar su funcionamiento en el nuevo host), balanceo
 de carga, tolerancia a fallos, etc.
 Es importante que la solución sea escalable, en este caso debe poder detectar
 automáticamente nuevos servidores conectados al cluster para proceder a
 su utilización.
\end_layout

\begin_layout Standard
El middleware recibe los trabajos entrantes al cluster y los redistribuye
 de manera que el proceso se ejecute más rápido y el sistema no sufra sobrecarga
s en un servidor.
 Esto se realiza mediante políticas definidas en el sistema (automáticamente
 o por un administrador) que le indican dónde y cómo debe distribuir los
 procesos, por un sistema de monitorización, el cual controla la carga de
 cada CPU y la cantidad de procesos en él.
\end_layout

\begin_layout Standard
El middleware también debe poder migrar procesos entre servidores con distintas
 finalidades.
 Debe ser capaz de balancear la carga, si un servidor está muy cargado de
 procesos y otro está ocioso, pueden transferirse procesos a este último
 para liberar de carga al primero y optimizar el funcionamiento.
 Además debe permitir al administrador realizar un mantenimiento de los
 servidores, si hay procesos corriendo en un servidor que necesita mantenimiento
 o una actualización, deberá ser posible migrar los procesos a otro y proceder
 a desconectar del cluster al primero.
 A su vez es el encargado de priorizar los trabajos.
 En caso de tener varios procesos corriendo en el cluster, pero uno de ellos
 de mayor importancia que los demás, puede migrarse este proceso a los servidore
s que posean más o mejores recursos para acelerar su procesamiento.
 
\end_layout

\begin_layout Standard
Los Middleware han aparecido de manera relativamente reciente en el mundo
 de la informática.
 Ganaron popularidad en los 1980s ya que eran la solución para integrar
 las nuevas aplicaciones con los sistemas antiguos (legacy systems), en
 todo caso, el término ha sido usado desde 1968.
 También facilitaba la computación distribuida, mediante la conexión de
 múltiples aplicaciones para crear una aplicación mucho mayor sobre una
 red.
\end_layout

\end_body
\end_document
