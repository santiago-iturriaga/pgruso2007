#LyX 1.4.4 created this file. For more info see http://www.lyx.org/
\lyxformat 245
\begin_document
\begin_header
\textclass article
\language spanish
\inputencoding auto
\fontscheme default
\graphics default
\paperfontsize default
\spacing single
\papersize default
\use_geometry false
\use_amsmath 1
\cite_engine basic
\use_bibtopic false
\paperorientation portrait
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\defskip medskip
\quotes_language swedish
\papercolumns 2
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\end_header

\begin_body

\begin_layout Title
Estado del Arte
\end_layout

\begin_layout Title
Cluster de Computadores de Alto Desempeño con Acceso Remoto
\end_layout

\begin_layout Title
Carrera de Ingeniería en Computación
\end_layout

\begin_layout Title
Facultad de Ingeniería
\end_layout

\begin_layout Author
Santiago Iturriaga, Paulo Maya, Damian Pintos
\end_layout

\begin_layout Section*
Resumen
\end_layout

\begin_layout Section*
Introducción
\end_layout

\begin_layout Section*
Computación de Alto Rendimiento
\end_layout

\begin_layout Paragraph
El campo de la computación de alto rendimiento es muy importante en la resolució
n a problemas complejos.
 
\end_layout

\begin_layout Paragraph
La computación de alto rendimiento se apoya en tecnologías como los clusters,
 supercomputadores o mediante el uso de la computación paralela.
 
\end_layout

\begin_layout Subsection*
Computación Distribuida
\end_layout

\begin_layout Paragraph
La computación distribuida es un modelo para resolver problemas de computación
 masiva utilizando un gran número de computadoras en una infraestructura
 de telecomunicaciones distribuida.
\end_layout

\begin_layout Paragraph
La informática distribuida consiste en compartir recursos heterogéneos (basadas
 en distintas plataformas, arquitecturas de equipos y programas, lenguajes
 de programación), situados en distintos lugares y pertenecientes a diferentes
 dominios de administración sobre una red que utiliza estándares abiertos.
 
\end_layout

\begin_layout Paragraph
La computación distribuida ha sido diseñada para resolver problemas demasiado
 grandes para cualquier supercomputadora y main-frame, manteniendose la
 flexibilidad de trabajar en múltiples problemas más pequeños.
 Por lo tanto, la computación en grid es naturalmente un entorno multi-usuario;
 por ello, las técnicas de autorización segura son esenciales antes de permitir
 que los recursos informáticos sean controlados por usuarios remotos.
\end_layout

\begin_layout Section*
Clusters
\end_layout

\begin_layout Paragraph
El término cluster se aplica a los conjuntos de computadoras que se comportan
 como si fuesen una única computadora.
 Hoy en día tiene un papel importante en aplicaciones científicas y de ingenierí
a, comerciales, simulaciones, etc.
\end_layout

\begin_layout Paragraph
La tecnología de clusters ha evolucionado apoyándose en actividades que
 van desde aplicaciones de supercómputo y software de misiones críticas,
 servidores Web y comercio electrónico, hasta bases de datos de alto rendimiento.
\end_layout

\begin_layout Paragraph
El uso de clusters surge gracias a la convergencia de varias tendencias
 actuales como la disponibilidad de microprocesadores económicos de alto
 rendimiento y redes de alta velocidad, la existentica de herramientas para
 cómputo distribuido de alto rendimiento, así como la creciente necesidad
 de potencia computacional para aplicaciones que la requieran.
\end_layout

\begin_layout Paragraph
Un cluster es un grupo de múltiples ordenadores unidos mediante una red
 de alta velocidad, de tal forma que el conjunto es visto como un único
 ordenador, más potente que los comunes de escritorio.
 
\end_layout

\begin_layout Paragraph
Se espera de un cluster que presente combinaciones de los siguientes característ
icas:
\end_layout

\begin_layout Enumerate
Alto rendimiento
\end_layout

\begin_layout Enumerate
Alta disponibilidad
\end_layout

\begin_layout Enumerate
Equilibrio de carga 
\end_layout

\begin_layout Enumerate
Escalabilidad 
\end_layout

\begin_layout Paragraph
La construcción de los cluster es muy fácil y económica, debido a su flexibilida
d: pueden tener todos la misma configuración de hardware y sistema operativo
 (cluster homogéneo), diferente rendimiento pero con arquitecturas y sistemas
 operativos similares (cluster semi-homogéneo), o tener diferente hardware
 y sistema operativo (cluster heterogéneo).
\end_layout

\begin_layout Paragraph
Se pueden construir cluster con ordenadores personales desechados por "anticuado
s" que consiguen competir en capacidad de cálculo con superordenadores carísimos.
\end_layout

\begin_layout Paragraph
Es necesario proveer un sistema para el manejo del cluster, el cual se encargue
 de interactuar con el usuario y los procesos que corren en él para optimizar
 el funcionamiento.
\end_layout

\begin_layout Subsubsection*
Cluster de alto rendimiento
\end_layout

\begin_layout Paragraph
Un cluster de alto rendimiento está diseñado para dar altas prestaciones
 en cuanto a capacidad de cálculo.
\end_layout

\begin_layout Paragraph
Los motivos para utilizar un cluster de alto rendimiento son:
\end_layout

\begin_layout Itemize
el tamaño del problema por resolver y
\end_layout

\begin_layout Itemize
el precio de la máquina necesaria para resolverlo.
\end_layout

\begin_layout Paragraph
Por medio de un cluster se pueden conseguir capacidades de cálculo superiores
 a las de un ordenador más caro.
\end_layout

\begin_layout Paragraph
Para garantizar esta capacidad de cálculo, los problemas necesitan ser paraleliz
ables, ya que el método con el que los clusters agilizan el procesamiento
 es dividir el problema en problemas más pequeños y calcularlos en los nodos.
\end_layout

\begin_layout Subsubsection*
Cluster de alta disponibilidad
\end_layout

\begin_layout Paragraph
Un cluster de alta disponibilidad se caracterizan por compartir los discos
 de almacenamiento de datos y por estar constantemente monitorizándose entre
 sí.
 
\end_layout

\begin_layout Paragraph
Podemos dividirlo en dos clases:
\end_layout

\begin_layout Itemize
Alta disponibilidad de infrestructura
\end_layout

\begin_layout Itemize
Alta disponibilidad de aplicación
\end_layout

\begin_layout Subsubsection*
Cluster de balanceo de carga
\end_layout

\begin_layout Paragraph
Un cluster de equilibrio de carga o de cómputo adaptativo está compuesto
 por uno o más ordenadores que actúan como frontend del cluster, y que se
 ocupan de repartir las peticiones de servicio que reciba el cluster, a
 otros ordenadores del cluster que forman el back-end de éste.
 
\end_layout

\begin_layout Subsubsection*
Escalabilidad
\end_layout

\begin_layout Paragraph
La escalabilidad es la propiedad deseable de un sistema, una red o un proceso,
 que indica su habilidad para, o bien manejar el crecimiento continuo de
 trabajo de manera fluida, o bien para estar preparado para hacerse más
 grande sin perder calidad en los servicios ofrecidos.
\end_layout

\begin_layout Paragraph
Las características más destacadas de este tipo de cluster son:
\end_layout

\begin_layout Itemize
Se puede ampliar su capacidad fácilmente añadiendo más ordenadores al cluster.
\end_layout

\begin_layout Itemize
Robustez.
 Ante la caída de alguno de los ordenadores del cluster el servicio se puede
 ver mermado, pero mientras haya ordenadores en funcionamiento, éstos seguirán
 dando servicio.
\end_layout

\begin_layout Section*
Programación Paralela
\end_layout

\begin_layout Paragraph
La programación paralela es una técnica de programación basada en la ejecución
 simultánea, bien sea en un mismo ordenador (con uno o varios procesadores)
 o en un cluster de ordenadores, en cuyo caso se denomina computación distribuid
a.
 Al contrario que en la programación concurrente, esta técnica enfatiza
 la verdadera simultaneidad en el tiempo de la ejecución de las tareas.
\end_layout

\begin_layout Paragraph
Los sistemas con multiprocesador y multicomputadores consiguen un aumento
 del rendimiento si se utilizan estas técnicas.
 En los sistemas monoprocesador el beneficio en rendimiento no es tan evidente,
 ya que la CPU es compartida por múltiples procesos en el tiempo, lo que
 se denomina multiplexación o multiprogramación.
\end_layout

\begin_layout Paragraph
El mayor problema de la computación paralela radica en la complejidad de
 sincronizar unas tareas con otras, ya sea mediante secciones críticas,
 semáforos o paso de mensajes, para garantizar la exclusión mutua en las
 zonas del código en las que sea necesario.
\end_layout

\begin_layout Standard
Aplicaciones demandantes de recursos
\end_layout

\begin_layout Standard
Podemos hacer una division de las aplicaciones que requieren una demanda
 de recusrsos computaionales importantes de la siguiente manera.
\end_layout

\begin_layout Standard
Aplicacions de calculo intencivas
\end_layout

\begin_layout Standard
Son aplicaciones que requieren un alto numero de ciclos de máquinas, estas
 son las que han impulsado
\end_layout

\begin_layout Standard
el desarrollo de supercomputadores.
 Son típicas en ciencias e ingeniería, aunque recientemente
\end_layout

\begin_layout Standard
han aparecido en otras áreas como simulación financiera y económica.
 Dependen grandemente de
\end_layout

\begin_layout Standard
la velocidad y el procesamiento de punto flotantes de los supercomputadores.
 
\end_layout

\begin_layout Standard
Algunos ejemplos son:
\end_layout

\begin_layout Standard
1.
 Dinámica de fluidos computacional.
\end_layout

\begin_layout Standard
2.
 Simulaciones electromagnéticas.
\end_layout

\begin_layout Standard
3.
 Modelado ambiental.
\end_layout

\begin_layout Standard
4.
 Dinámica estructural.
\end_layout

\begin_layout Standard
5.
 Modelado biológico.
\end_layout

\begin_layout Standard
6.
 Dinámica molecular.
\end_layout

\begin_layout Standard
7.
 Simulación de redes.
\end_layout

\begin_layout Standard
8.
 Modelado financiero y económico.
\end_layout

\begin_layout Standard
Aplicaciones de almacenemiento masivo
\end_layout

\begin_layout Standard
Dependen de la capacidad para almacenar y procesar grandes cantidades de
 información.
 Requieren de un acceso rápido y seguro a una masa considerable de datos
\end_layout

\begin_layout Standard
almacenados.
 
\end_layout

\begin_layout Standard
Algunas de ellas son:
\end_layout

\begin_layout Standard
1.
 Análisis de data sísmica.
\end_layout

\begin_layout Standard
2.
 Procesamiento de imágenes.
\end_layout

\begin_layout Standard
3.
 Minería de datos.
\end_layout

\begin_layout Standard
4.
 Análisis estadístico de datos.
\end_layout

\begin_layout Standard
5.
 Análisis de mercados.
\end_layout

\begin_layout Standard
Aplicaciones exigentes comunicacionalmente
\end_layout

\begin_layout Standard
Estas son relativamente nuevas y pueden ser llamadas servicios por demanda.
 Requieren de
\end_layout

\begin_layout Standard
recursos computacionales conectados por redes con anchos de banda considerables.
\end_layout

\begin_layout Standard
Ejemplos:
\end_layout

\begin_layout Standard
1.
 Procesamiento de transacciones en línea.
\end_layout

\begin_layout Standard
2.
 Sistemas colaborativos.
\end_layout

\begin_layout Standard
3.
 Texto por demanda.
\end_layout

\begin_layout Standard
4.
 Vídeo por demanda.
\end_layout

\begin_layout Standard
5.
 Imágenes por demanda.
\end_layout

\begin_layout Standard
6.
 Simulación por demanda.
\end_layout

\begin_layout Standard
Obviamente que todas las aplicaciones anteriores dependen en cierto grado
 de cada uno de los
\end_layout

\begin_layout Standard
aspectos computacionales mencionados: poder de computo, capacidades de almacenam
iento y
\end_layout

\begin_layout Standard
eficientes canales de comunicación, sin embargo las podemos agrupar por
 su característica
\end_layout

\begin_layout Standard
dominante.
\end_layout

\begin_layout Standard
Sistemas de sistemas
\end_layout

\begin_layout Standard
Las aplicaciones en este grupo combinan en forma más compleja las característica
s anteriores
\end_layout

\begin_layout Standard
y dependen, en muchos casos, de sistemas computacionales integrados diseñados
\end_layout

\begin_layout Standard
primordialmente para ellas.
 
\end_layout

\begin_layout Standard
Ejemplos:
\end_layout

\begin_layout Standard
1.
 Soporte a decisiones corporativas y gubernamentales.
\end_layout

\begin_layout Standard
2.
 Control de sistemas a tiempo real.
\end_layout

\begin_layout Standard
3.
 Banca electrónica.
\end_layout

\begin_layout Standard
4.
 Compras electrónicas.
\end_layout

\begin_layout Standard
5.
 Educación.
\end_layout

\begin_layout Standard
Existe una alta correspondencia entre la evolución de tecnologías informaticas
 y el
\end_layout

\begin_layout Standard
desarrollo de aplicaciones; en particular el hardware tiene gran influencia
 en el éxito de ciertas
\end_layout

\begin_layout Standard
áreas.
 La aplicaciones intensivas en cálculo fueron estimuladas principalmente
 por máquinas
\end_layout

\begin_layout Standard
vectoriales y procesadores masivamente paralelos.
 Las aplicaciones de almacenamiento masivo
\end_layout

\begin_layout Standard
han sido guiadas por dispositivos de almacenamiento como RAID y robots de
 cintas.
 Las
\end_layout

\begin_layout Standard
aplicaciones exigentes comunicacionales como herramientas colaborativas
 basadas en WWW y
\end_layout

\begin_layout Standard
servicios por demanda en línea originalmente surgieron con las LAN y estan
 creciendo
\end_layout

\begin_layout Standard
drásticamente con Internet.
\end_layout

\begin_layout Standard
Organizacion de computadores
\end_layout

\begin_layout Standard
La organización de los procesadores o red se refiere a como se conectan
 o enlazan los
\end_layout

\begin_layout Standard
procesadores o nodos en un computador paralelo.
\end_layout

\begin_layout Standard
Existen varios criteriospara evaluar los distintos diseños de organizacion:
\end_layout

\begin_layout Standard
1) Diámetro: viene dado por la mayor distancia entre dos nodos.
 Mientras menor
\end_layout

\begin_layout Standard
sea el diámetro menor será el tiempo de comunicación entre nodos.
\end_layout

\begin_layout Standard
2) Ancho de bisección de la red: es el menor número de enlaces que deben
 ser removidos
\end_layout

\begin_layout Standard
para dividir la red por la mitad.
 Un ancho de bisección alto puede reducir el tiempo de comunicación cuando
 el movimiento de datos es sustancial, y un ancho
\end_layout

\begin_layout Standard
de bisección alto hace el sistema más tolerante a fallas debido a que defectos
 en un nodo no hacen inoperable a todo el sistema.
\end_layout

\begin_layout Standard
3) Es preferible que el número de enlaces por nodo sea una constante independien
te del
\end_layout

\begin_layout Standard
tamaño de la red, ya que hace más fácil incrementar el número de nodos.
\end_layout

\begin_layout Standard
4) Es preferible que la longitud máxima de los enlaces sea una constante
 independiente del
\end_layout

\begin_layout Standard
tamaño de la red, ya que hace más fácil añadir nodos.
 
\end_layout

\begin_layout Standard
5) Redes estáticas y dinámicas.
 En las redes estáticas la topología de interconexión se
\end_layout

\begin_layout Standard
define cuando se construye la máquina.
 Si la red es dinámica, la interconexión puede
\end_layout

\begin_layout Standard
variar durante la ejecución de un programa o entre la ejecución de programas.
\end_layout

\begin_layout Standard
A continuacion veremos algunos tipos de disenos de redes de procesadores.
\end_layout

\begin_layout Standard
BUS Y ETHERNET
\end_layout

\begin_layout Standard
En una red donde los procesadores comparten el mismo recurso de comunicación:
\end_layout

\begin_layout Standard
el bus.
 
\end_layout

\begin_layout Standard
Esta arquitectura es fácil y económica de implementar, pero es altamente
 no escalable ya
\end_layout

\begin_layout Standard
que solo un procesador puede usar el bus en un momento dado; a medida que
 se incrementa el
\end_layout

\begin_layout Standard
número de procesadores, el bus se convierte en un cuello de botella debido
 a la congestión.
 
\end_layout

\begin_layout Standard
Mallas
\end_layout

\begin_layout Standard
Al igual que el bus (o ethernet), las mallas son fáciles y económicas de
 implementar, sin
\end_layout

\begin_layout Standard
embargo el diámetro se incrementa al añadir nodos.
 En las mallas de dimensión 1, si los dos
\end_layout

\begin_layout Standard
nodos extremos también son conectados, entonces se tiene un anillo
\end_layout

\begin_layout Standard
Mallas de 2 dimensiones y de 3 dimensiones son comunes en computación paralela
\end_layout

\begin_layout Standard
y tiene la ventaja de que pueden ser construidas sin conexiones largas.
 El diámetro de las mallas
\end_layout

\begin_layout Standard
puede ser reducido a la mitad si se extiende la malla con conexiones toroidales
 de forma que los
\end_layout

\begin_layout Standard
procesadores en los bordes también estén conectados con vecinos.
 Esto sin embargo
\end_layout

\begin_layout Standard
presenta dos desventajas: a) conexiones más largas son requeridas y b) un
 subconjunto de un
\end_layout

\begin_layout Standard
torus no es un torus y los beneficios de esta interconexión se pierden si
 la máquina es
\end_layout

\begin_layout Standard
particionada entre varios usuarios.
\end_layout

\begin_layout Standard
MARIPOSA
\end_layout

\begin_layout Standard
Figura
\end_layout

\begin_layout Standard
ARBOLES BINARIOS
\end_layout

\begin_layout Standard
Son particularmente útiles en problemas de ordenamiento, multiplicación
\end_layout

\begin_layout Standard
de matrices, y algunos problemas en los que los tiempos sw solución crecen
 exponencialmente con el
\end_layout

\begin_layout Standard
tamaño del problema (NP-complejos).
 
\end_layout

\begin_layout Standard
PIRAMIDES
\end_layout

\begin_layout Standard
Estas redes intentan combinar las ventajas de las mallas y los arboles,
 se incrementa la tolerancia a fallas y el número de vias de comunicación.
\end_layout

\begin_layout Standard
HIPERCUBO
\end_layout

\begin_layout Standard
Un hipercubo puede ser considerado como una malla con conexiones largas
 adicionales, estas conexiones reducen el diámetro e incrementan el ancho
 de bisección.
 
\end_layout

\begin_layout Standard
Se puede definir recursibamente un hipercubo de la siguiente manera: un
 hipercubo de dimensión-cero es un único procesador
\end_layout

\begin_layout Standard
y un hipercubo de dimensión-uno conecta dos hipercubos de dimensión-cero.
 En general, un
\end_layout

\begin_layout Standard
hipercubo de dimensión d+1 con 2d+1 nodos, se construye conectando los procesado
res
\end_layout

\begin_layout Standard
respectivos de dos hipercubos de dimensión d.
 
\end_layout

\begin_layout Standard
OMEGA
\end_layout

\begin_layout Standard
La Figura 12 muestra una red omega de 3 etapas que conecta 8 procesadores).
 La red está
\end_layout

\begin_layout Standard
formada por crossbar switches 2x2.
 Los switches tiene cuatro estados posibles: recto, cruzado,
\end_layout

\begin_layout Standard
broadcast superior y broadcast inferior; que pueden ser configurados dependiendo
 de la
\end_layout

\begin_layout Standard
conexión que se desea (Figura 13).
 Debido a esto, estas topologías se llaman dinámicas o
\end_layout

\begin_layout Standard
reconfigurables.
 Los switches son unidireccionales y debemos ver la red plegada en donde
 los
\end_layout

\begin_layout Standard
procesadores de la izquierda y la derecha son los mismos.
 Estas redes reducen considerablemente
\end_layout

\begin_layout Standard
la competencia por ancho de banda, pero son altamente no escalables y costosas.
 El highperformance-
\end_layout

\begin_layout Standard
switch de la SP2 es una red omega.
\end_layout

\begin_layout Standard
FIBRAS DE INTERCONEXION
\end_layout

\begin_layout Standard
Estas so un conjunto de switches, llamados routers, enlazados por distintas
 configuraciones o topologías.
\end_layout

\begin_layout Standard
DISEÑO DE ALGORITMOS PARALELOS
\end_layout

\begin_layout Standard
El diseño de algoritmos paralelos involucra cuatro etapas, las cuales se
 presentan como
\end_layout

\begin_layout Standard
secuenciales pero que en la práctica no lo son.
\end_layout

\begin_layout Standard
1) Partición: El cómputo y los datos sobre los cuales se opera se descomponen
 en tareas.
 Se
\end_layout

\begin_layout Standard
ignoran aspectos como el número de procesadores de la máquina a usar y se
 concentra la
\end_layout

\begin_layout Standard
atención en explotar oportunidades de paralelismo.
\end_layout

\begin_layout Standard
2) Comunicación: Se determina la comunicación para coordinar las tareas.
 Se
\end_layout

\begin_layout Standard
definen estructuras y algoritmos de comunicación.
\end_layout

\begin_layout Standard
3) Agrupación: Se evalua en terminos de eficiencia y costos de implementacion
 a las dos etapas anteriores.
 
\end_layout

\begin_layout Standard
se agrupan tareas pequeñas en tareas más grandes.
\end_layout

\begin_layout Standard
4) Asignación: Cada tarea es asignada a un procesador tratando de maximizar
 la utilización
\end_layout

\begin_layout Standard
de los procesadores y de reducir el costo de comunicación.
 La asignación puede ser
\end_layout

\begin_layout Standard
estática (se establece antes de la ejecución del programa) o en tiempo de
 ejecución
\end_layout

\begin_layout Standard
mediante algoritmos de balanceo de carga.
\end_layout

\begin_layout Standard
Particion
\end_layout

\begin_layout Standard
En la etapa de partición se buscan oportunidades de paralelismo y se trata
 de subdividir el
\end_layout

\begin_layout Standard
problema lo más finamente posible.
 Se dividen tanto los cómputos como los datos.
 
\end_layout

\begin_layout Standard
Existen dos formas de descomposicion.
\end_layout

\begin_layout Standard
Descomposición del dominio: se centra en los datos.
 Se determina la partición
\end_layout

\begin_layout Standard
apropiada de los datos y luego se trabaja en los cómputos asociados con
 los datos.
\end_layout

\begin_layout Standard
Descomposición funcional: es el contrario al enfoque anterior, primero se
 descomponen los
\end_layout

\begin_layout Standard
cómputos y luego se ocupa de los datos.
\end_layout

\begin_layout Standard
En el proceso de particion existen aspectos a tener en cuenta: 
\end_layout

\begin_layout Standard
-el orden de tareas debe ser por lo menos superior al numero de procesadores
 para tener flexibilidad en etapas siguientes
\end_layout

\begin_layout Standard
-evitar cómputos y almacenamientos redundantes
\end_layout

\begin_layout Standard
-las tareas deben ser de tamaños equivalentes para facilitar el balanceo
\end_layout

\begin_layout Standard
de la carga de los procesadores.
\end_layout

\begin_layout Standard
-El número de tareas debe ser proporcional al tamaño del problema
\end_layout

\begin_layout Standard
Comunicación
\end_layout

\begin_layout Standard
El proceso de partición de tareas no es independiente del proceso de comunicació
n.
 En esta se especifica como los datos serán transferidos o compartidos entre
 tareas.
\end_layout

\begin_layout Standard
La comunicación puede ser definida en dos fases.
 Primero se definen los canales que conectan las tareas.
 Segundo
\end_layout

\begin_layout Standard
se especifica la información o mensajes que deben ser enviado y recibidos
 en estos canales.
\end_layout

\begin_layout Standard
Dependiendo de si estamos en el caso de memoria distribuida o memoria compartida
 dependera la forma de atacar la comunicación entre tareas varía.
\end_layout

\begin_layout Standard
En un ambientes de memoria distribuida, las tareas tiene una identificación
 única y interactuan enviando y recibiendo mensajes hacia y desde tareas
 específicas.
 Las librerías más conocidas para implementar el pase de mensajes en ambientes
 de memoria distribuida son: MPI (Message Passing Interface) y PVM (Parallel
 Virtual Machine).
\end_layout

\begin_layout Standard
En ambientes de memoria compartida no existe la noción de pertenencia y
 el envío de datos
\end_layout

\begin_layout Standard
no se dá como tal.
 Todas las tareas comparten la misma memoria.
\end_layout

\begin_layout Standard
Semáforos, semáforos binarios, barreras y otros mecanismos de sincronizacion
 son usados para controlar el acceso a la
\end_layout

\begin_layout Standard
memoria compartida y coordinar las tareas.
\end_layout

\begin_layout Standard
En esta etapa hay que tener en cuenta los siguientes aspectos:
\end_layout

\begin_layout Standard
-las tareas deben efectuar aproximadamente el mismo número de operaciones
 de
\end_layout

\begin_layout Standard
comunicación.
 De otra forma es muy probable que el algoritmo no sea extensible a
\end_layout

\begin_layout Standard
problemas mayores ya que habrán cuellos de botella.
\end_layout

\begin_layout Standard
-la comunicación entre tareas debe ser tan pequeña como sea posible.
\end_layout

\begin_layout Standard
-las operaciones de comunicación deben poder proceder concurrentemente.
\end_layout

\begin_layout Standard
-los cómputos de diferentes tareas deben poder proceder concurrentemente.
\end_layout

\begin_layout Standard
AGRUPACION
\end_layout

\begin_layout Standard
En las dos tareas anteriores el algoritmo resultante es aún abstracto en
 el sentido de que no se tomó en cuenta
\end_layout

\begin_layout Standard
la máquina sobre el cual correrá.
 En este proceso se busca un algoritmo concreto, que corra eficientemente
 sobre cierta clase
\end_layout

\begin_layout Standard
de computadores.
 
\end_layout

\begin_layout Standard
En particular se considera si es útil agrupar tareas y si vale la pena replicar
 datos y/o cómputos.
\end_layout

\begin_layout Standard
En el proceso de partición se trata de establecer el mayor número posible
 de tareas con la 
\end_layout

\begin_layout Standard
intensión de maximizar el paralelismo.
 
\end_layout

\begin_layout Standard
Esto no necesariamente produce un algoritmo eficiente ya que el costo de
 comunicación puede ser significativo.
 
\end_layout

\begin_layout Standard
Mediante la agrupación de tareas se puede reducir la cantidad de datos a
 enviar y así reducir el número de
\end_layout

\begin_layout Standard
mensajes y el costo de comunicación.
\end_layout

\begin_layout Standard
Se puede intentar replicar cómputos y/o datos para reducir los requerimientos
 de comunicación.
 
\end_layout

\begin_layout Standard
Aspectos a considerar en esta etapa:
\end_layout

\begin_layout Standard
-chequear si la agrupación redujo los costos de comunicación.
\end_layout

\begin_layout Standard
-si se han replicado cómputos y/o datos, se debe verificar que los beneficios
 son superiores
\end_layout

\begin_layout Standard
a los costos.
\end_layout

\begin_layout Standard
-se debe verificar que las tareas resultantes tengan costos de computo y
 comunicación
\end_layout

\begin_layout Standard
similares.
\end_layout

\begin_layout Standard
- revisar si el número de tareas es extensible con el tamaño del problema.
\end_layout

\begin_layout Standard
-si el agrupamiento ha reducido las oportunidades de ejecución concurrente,
 se debe
\end_layout

\begin_layout Standard
verificar que aun hay suficiente concurrencia y posiblemente considerar
 diseños
\end_layout

\begin_layout Standard
alternativos.
\end_layout

\begin_layout Standard
-nalizar si es posible reducir aun más el número de tareas sin introducir
 desbalances de
\end_layout

\begin_layout Standard
cargas o reducir la extensibilidad.
\end_layout

\begin_layout Standard
ASIGNACION
\end_layout

\begin_layout Standard
En este proceso se determina en que procesador se ejecutará cada tarea.
 Este problema
\end_layout

\begin_layout Standard
no se presenta en máquinas de memoria compartida tipo UMA.
 Estas proveen asignación
\end_layout

\begin_layout Standard
dinámica de procesos y los procesos que necesitan de un CPU están en una
 cola de procesos
\end_layout

\begin_layout Standard
listos.
 Cada procesador tiene acceso a esta cola y puede correr el próximo proceso.
 No
\end_layout

\begin_layout Standard
consideraremos más este caso.
\end_layout

\begin_layout Standard
Para el momento no hay mecanismos generales de asignación de tareas para
 máquinas
\end_layout

\begin_layout Standard
distribuidas.
 Esto continúa siendo un problema difícil y que debe ser atacado explícitamente
 a la
\end_layout

\begin_layout Standard
hora de diseñar algoritmos paralelos.
\end_layout

\begin_layout Standard
La asignación de tareas puede ser estática o dinámica.
 En la asignación estática, las tareas
\end_layout

\begin_layout Standard
son asignadas a un procesador al comienzo de la ejecución del algoritmo
 paralelo y corren ahí
\end_layout

\begin_layout Standard
hasta el final.
 La asignación estática en ciertos casos puede resultar en un tiempo de
 ejecución
\end_layout

\begin_layout Standard
menor respecto a asignaciones dinámicas y también puede reducir el costo
 de creación de
\end_layout

\begin_layout Standard
procesos, sincronización y terminación.
\end_layout

\begin_layout Standard
En la asignación dinámica se hacen cambios en la distribución de las tareas
 entre los
\end_layout

\begin_layout Standard
procesadores a tiempo de ejecución, o sea, hay migración de tareas a tiempo
 de ejecución.
 Esto
\end_layout

\begin_layout Standard
es con el fin de balancear la carga del sistema y reducir el tiempo de ejecución.
 Sin embargo, el
\end_layout

\begin_layout Standard
costo de balanceo puede ser significativo y por ende incrementar el tiempo
 de ejecución.
 Entre
\end_layout

\begin_layout Standard
los algoritmos de balanceo de carga están los siguientes:
\end_layout

\begin_layout Standard
Balanceo centralizado: un nodo ejecuta el algoritmo y mantiene el estado
 global del sistema.
\end_layout

\begin_layout Standard
Este método no es extensible a problemas más grandes ya que el nodo encargado
 del balanceo se
\end_layout

\begin_layout Standard
convierte en un cuello de botella.
\end_layout

\begin_layout Standard
Balanceo completamente distribuido: cada procesador mantiene su propia visión
 del
\end_layout

\begin_layout Standard
sistema intercambiando información con sus vecinos y así hacer cambios locales.
 El costo de
\end_layout

\begin_layout Standard
balanceo se reduce pero no es óptimo debido a que solo se dispone de información
 parcial.
\end_layout

\begin_layout Standard
Balanceo semi-distribuido: divide los procesadores en regiones, cada una
 con un algoritmo
\end_layout

\begin_layout Standard
centralizado local.
 Otro algoritmo balancea la carga entre las regiones.
\end_layout

\begin_layout Standard
El balanceo puede ser iniciado por envío o recibimiento.
 Si es balanceo iniciado por envío,
\end_layout

\begin_layout Standard
un procesador con mucha carga envía trabajo a otros.
 Si es balanceo iniciado por recibimiento,
\end_layout

\begin_layout Standard
un procesador con poca carga solicita trabajo de otros.
 Si la carga por procesador es baja o
\end_layout

\begin_layout Standard
mediana, es mejor el balanceo iniciado por envío.
 Si la carga es alta se debe usar balanceo
\end_layout

\begin_layout Standard
iniciado por recibimiento.
 De lo contrario, en ambos casos, se puede producir una fuerte
\end_layout

\begin_layout Standard
migración innecesaria de tareas.
\end_layout

\begin_layout Section*
Relevamiento de tecnologias
\end_layout

\begin_layout Section
OpenMosix, OpenSSI y Kerrighed
\end_layout

\begin_layout Section
Condor
\end_layout

\begin_layout Section
OpenPBS
\end_layout

\begin_layout Section
SLURM
\end_layout

\begin_layout Section
Sun grid engine 6.1
\end_layout

\begin_layout Subsection
Requerimientos
\end_layout

\begin_layout Itemize
Master: 100 MB de memoria disponible 500 MB de disco disponible
\end_layout

\begin_layout Itemize
Host de ejecución: 20 MB de memoria disponible 100 MB de disco disponible
\end_layout

\begin_layout Itemize
Sistemas operativos soportados:
\end_layout

\begin_deeper
\begin_layout Itemize
Solaris 10, 9, and 8 SPARC 
\end_layout

\begin_layout Itemize
Solaris 10 and 9 x86
\end_layout

\begin_layout Itemize
Solaris 10 x64
\end_layout

\begin_layout Itemize
Apple Mac OS X 10.4 (Tiger) PPC
\end_layout

\begin_layout Itemize
Apple Mac OS X 10.4 (Tiger) x86
\end_layout

\begin_layout Itemize
Hewlett Packard HP-UX 11.00 o superior (incluido HP-UX IA64)
\end_layout

\begin_layout Itemize
IBM AIX 5.1, 5.3
\end_layout

\begin_layout Itemize
Linux x86, kernel 2.4, 2.6, glibc >= 2.3.2
\end_layout

\begin_layout Itemize
Linux x64, kernel 2.4, 2.6, glibc >= 2.3.2
\end_layout

\begin_layout Itemize
Linux IA64, kernel 2.4, 2.6, glibc >= 2.3.2
\end_layout

\begin_layout Itemize
Silicon Graphics IRIX 6.5
\end_layout

\begin_layout Itemize
Microsoft Windows Server 2003
\end_layout

\begin_layout Itemize
Windows XP Professional with Service Pack 1 o superior
\end_layout

\begin_layout Itemize
Windows 2000 Server with Service Pack 3 o superior
\end_layout

\begin_layout Itemize
Windows 2000 Professional with Service Pack 3 o superior
\end_layout

\end_deeper
\begin_layout Itemize
Plataformas
\end_layout

\begin_deeper
\begin_layout Itemize
SPARC Ultra III
\end_layout

\begin_layout Itemize
SPARC Ultra IV
\end_layout

\begin_layout Itemize
AMD64 x86
\end_layout

\begin_layout Itemize
Mac
\end_layout

\end_deeper
\begin_layout Subsection
Características generales
\end_layout

\begin_layout Itemize
Permite limitar el máximo numero de trabajos por usuario, grupo y proyecto
 o recursos como colas, host, memoria y licencias de software.
 
\end_layout

\begin_layout Itemize
Expresiones booleanas : permiten al usuario especificar los recursos que
 requerido para un trabajo determinado usando expresiones logicas.
 Por ejemplo, un usuario puede requerir que un trabajo corra en un host
 que cumpla la condición 
\begin_inset Quotes eld
\end_inset

Solaris o Linux pero no Linux en IA64
\begin_inset Quotes erd
\end_inset

.
 
\end_layout

\begin_layout Itemize
Distributed Resource Management Application API (DRMAA) es un conjunto de
 APIs standard desarrollado por Global Grid Forum para application builders,
 portal builders e ISV's.
 La versión 6.1 soporta los últimos C y Java bindings de DRMAA 1.0.
 Adicionalmente, es provisto de compatibilidad hacia atrás para: DRMAA 0.5
 Java binding y DRMAA 0.95 C binding.
\end_layout

\begin_layout Itemize
Guarda la información referida a la cuenta de cada trabajo en una base de
 datos relacional (soportando Oracle, MySQL y PostgreSQL).
\end_layout

\begin_layout Itemize
Una cola podria abarcar mas de un host de ejecucion.
 
\end_layout

\begin_layout Itemize
La grilla es rellenada con los trabajos mas chicos mientras los trabajos
 mas grandes estan siendo programados para ejecutarse.
 
\end_layout

\begin_layout Itemize
Provee ejecución repetitiva de el mismo (o muy similar) conjunto de operaciones,
 por ejemplo durante el renderizado de multiples frames.
 
\end_layout

\begin_layout Itemize
Maneja aplicaciones paralelas (MPI o PVM habilitados) a travez de una interface
 dedicada.
 
\end_layout

\begin_layout Itemize
Permite la distribución de recursos a equipos o departamentos, por ejemplo
 proporcionalmente a su contribución económica.
 
\end_layout

\begin_layout Itemize
Código con una complejidad alta.
 
\end_layout

\begin_layout Itemize
Sistema integrado, no muestra facilidades a la hora de dividirlo en subsistemas.
\end_layout

\begin_layout Subsection
Resumen
\end_layout

\begin_layout Standard
Sun grid engine 6.1 provee la mayoría de las funcionalidades requeridas para
 el proyecto.
 Por otro lado, tiene como desventaja el ser un único gran paquete indivisible,
 lo cual hace muy difícil cualquier adaptación o modificación de su funcionamien
to.
 
\end_layout

\begin_layout Standard
Si nos basamos en la historia reciente del producto, en una versión anterior
 se encontró un problema de seguridad (un salto en las restricciones) y
 quienes lo estaban utilizando en ese momento descartaron la idea de buscar
 el problema y solucionarlo, limitándose sólamente a esperar que los creadores
 de la herramienta lo corrigieran.
 
\end_layout

\begin_layout Standard
Esto se debe a que la herramienta cuenta con un código muy complejo y dificil
 de modificar, lo que lo coloca como una opción poco vialble para ser utilizada
 dentro del proyecto propuesto.
\end_layout

\begin_layout Section
TORQUE
\end_layout

\begin_layout Standard
TORQUE (Terascale Open-source Resource and QUEue manager) se trata de un
 'fork' open-source de la versión 2.3.12 de OpenPBS mantenido por Cluster
 Resources.
 
\end_layout

\begin_layout Standard
Incorpora muchas mejoras con respecto al proyecto PBS original provistas
 por NCSA (National Center of Supercomputing Applications), OSC (Ohio Supercompu
ter Center), Sandia, PNNL (Pacific Northwest National Laboratory), y otros
 centros HPC junto con las mejoras desarrolladas por Cluster Resources.
\end_layout

\begin_layout Subsection
Requerimientos
\end_layout

\begin_layout Standard
Plataformas soportadas:
\end_layout

\begin_layout Itemize
Linux
\end_layout

\begin_layout Itemize
UNIX
\end_layout

\begin_layout Subsection
Características generales
\end_layout

\begin_layout Standard
Los trabajos son manejados en el cluster de la misma manera que lo hace
 OpenPBS.
 Cuenta con un conjunto de colas de trabajos que definen propiedades generales
 para los trabajos que contienen (p.ej.
 recursos disponibles, etc.) y al ingresar un trabajo al sistema, este debe
 especificar características especificas de si mismo que ayuden al sistema
 a planificar la ejecución del mismo (p.ej.
 nodos a utilizar, memoria máxima a utilizar, etc.).
 Con esta información (los datos de la cola a la que pertenece el trabajo
 y los datos específicos del trabajo en cuestión) el scheduler decide el
 momento en que un trabajo comienza a ejecutarse y con que recursos cuenta
 en cada instante.
\end_layout

\begin_layout Standard
Existen tres tipos de nodos en el sistema:
\end_layout

\begin_layout Itemize
Nodo Maestro
\end_layout

\begin_deeper
\begin_layout Standard
Es necesario que exista un nodo maestro en el sistema, en este nodo se debe
 ejecutar pbs_server.
 Dependiendo del sistema este nodo maestro puede encontrarse dedicado únicamente
 a este rol o compartir otros roles.
\end_layout

\end_deeper
\begin_layout Itemize
Nodos Interactivos
\end_layout

\begin_deeper
\begin_layout Standard
Los nodos interactivos proveen un punto de entrada al sistema para los usuarios.
 Es en estos nodos en que los usuarios puede ingresar tareas al sistema
 y monitorear su progreso.
 Estos nodos deben tener comandos como qsub, qhold, etc disponibles.
\end_layout

\end_deeper
\begin_layout Itemize
Nodos de computo
\end_layout

\begin_deeper
\begin_layout Standard
Estos son los responsables de la ejecución de los trabajos encolados en
 el sistema.
 En cada uno de estos nodos debe ejecutarse pbs_mom (Machine Oriented Mini-serve
r) que es el encargado de iniciar, detener y manejar los trabajos encolados.
\end_layout

\end_deeper
\begin_layout Standard
Torque cuenta con una interfaz de usuario de linea de comando (CLI) como
 principal manera de interactuar con el sistema, también cuenta con una
 interfaz gráfica para X-Windows y una biblioteca para desarrollo en C.
 Es posible utilizar bibliotecas desarrolladas por 3eros para otros lenguajes
 (p.ej.
 Perl o Python).
\end_layout

\begin_layout Subsection
Bibliotecas para programación paralela
\end_layout

\begin_layout Subsubsection
MPI (Message Passing Interface)
\end_layout

\begin_layout Standard
El soporte para bibliotecas tipo MPI se encuentra integrado en TORQUE, el
 sistema puede correr con cualquier implementación de MPI.
 Particularmente para MPICH existe un reemplazo para el script mpirun (mpirun
 se encuentra incluido en el paquete de mpich) llamado mpiexec.
 Mpiexec es usado para inicializar trabajos paralelos dentro de un sistema
 PBS.
 Los recursos utilizados por procesos paralelos son correctamente registrados
 cuando se utiliza mpiexec y se reporta su uso en el log del PBS, a diferencia
 de lo que sucede cuando se utiliza el script mpirun original.
\end_layout

\begin_layout Subsubsection
PVM (Parallel Virtual Machine)
\end_layout

\begin_layout Standard
Una de las principales desventajas de TORQUE es la dificultad que plantea
 el uso de la biblioteca PVM.
 A diferencia de MPI, el soporte para PVM no se encuentra integrado al sistema
 por lo que debe manejarse cuidadosamente.
 Para ejecutar una aplicación paralela utilizando PVM se debe iniciar el
 demonio pvmd en el script del trabajo, configurar los nodos esclavos para
 luego iniciar la ejecución del trabajo (todo esto puede realizarse utilizando
 mpiexec).
\end_layout

\begin_layout Subsection
Maui
\end_layout

\begin_layout Standard
TORQUE contiene la lógica necesaria para llevar a cabo la planificación
 de trabajos, pero se trata de una lógica muy simple que no resulta adecuada
 para un ambiente de producción.
 Básicamente el planificador que se encuentra incorporado a TORQUE maneja
 los trabajos como una cola FIFO (First-In First-Out).
 Para mejorar esto se utiliza Maui, una aplicación especializada en la planifica
ción de trabajos.
\end_layout

\begin_layout Standard
Maui se enfoca en la planificación de trabajos y deja la problemática de
 iniciar los trabajos y la interacción con los usuarios a los manejadores
 de recursos (distributed resource managers, DRM) como OpenPBS, TORQUE,
 SGE, etc.
\end_layout

\begin_layout Subsubsection
Requerimientos
\end_layout

\begin_layout Itemize
Hardware
\end_layout

\begin_deeper
\begin_layout Itemize
20-50 MB de RAM (para clusters de hasta 10 teraflops)
\end_layout

\begin_layout Itemize
>20 MB de disco duro para los fuentes, binarios, estadísticas y archivos
 de logs
\end_layout

\end_deeper
\begin_layout Itemize
Plataformas soportadas
\end_layout

\begin_deeper
\begin_layout Itemize
Linux
\end_layout

\begin_layout Itemize
AIX
\end_layout

\begin_layout Itemize
OSF/Tru-64
\end_layout

\begin_layout Itemize
Solaris
\end_layout

\begin_layout Itemize
HP-UX
\end_layout

\begin_layout Itemize
IRIX
\end_layout

\begin_layout Itemize
FreeBSD
\end_layout

\begin_layout Itemize
Other UNIX platforms
\end_layout

\end_deeper
\begin_layout Itemize
DRM soportados
\end_layout

\begin_deeper
\begin_layout Itemize
OpenPBS
\end_layout

\begin_layout Itemize
'Scalable' Open PBS
\end_layout

\begin_layout Itemize
PBSPro
\end_layout

\begin_layout Itemize
Sun Grid Engine (SGE)
\end_layout

\begin_layout Itemize
SGE Enterprise Edition
\end_layout

\begin_layout Itemize
LoadLeveler
\end_layout

\begin_layout Itemize
LSF
\end_layout

\begin_layout Itemize
BProc/Scyld
\end_layout

\begin_layout Itemize
Scalable System Software (SSSRM)
\end_layout

\end_deeper
\begin_layout Subsubsection
Características generales
\end_layout

\begin_layout Standard
El algoritmo de planificación de Maui soporta fairness, preemption, backfill,
 etc.
 y tiene una interfaz para la interacción con un allocation management externo.
 Un allocation manager (también conocido como allocation bank o cpu bank)
 funciona como un banco en el cual la moneda son los recursos del sistema
 (p.ej.
 procesadores, memoria, etc.) autorizando a los trabajos cierta cantidad
 de recursos.
\end_layout

\begin_layout Paragraph
Backfill
\end_layout

\begin_layout Standard
Backfill es un acercamiento en la planificación que permite ejecutar algunos
 trabajos 'desordenadamente' siempre y cuando estos no retrasen los trabajos
 de prioridad superior de la cola.
 Para determinar si un trabajo será retrasado, cada trabajo debe proveer
 una estimación de cuánto tiempo necesitará para su ejecución.
 Esta estimación, conocida como límite wallclock, es una valoración del
 tiempo desde el comienzo del trabajo hasta su final.
 Es a menudo sabio sobrestimar levemente este límite porque el planificador
 se puede configurar para matar a los trabajos que exceden sus límites del
 wallclock.
 Sin embargo, la sobrestimación demasiado grande del tiempo del wallclock
 de un trabajo evitará que el planificador pueda optimizar correctamente
 la cola de trabajo.
 Cuanto más exacto el límite del wallclock, mayor sera la posibilidad de
 que Maui encuentre agujeros en la planificación para comenzar a ejecutar
 su trabajo con mayor anticipación.
 
\end_layout

\begin_layout Paragraph
Gerenciamiento de asignación
\end_layout

\begin_layout Standard
Maui posee interfaces para sistemas de gerenciamiento de asignación tales
 como Gold de PNNL.
 Estos sistemas permiten que a cada usuario le sea asignada una porción
 de los recursos totales de cálculo disponibles en el sistema.
 Estos sistemas trabajan asociando a cada usuario a unas o más cuentas.
 Cuando se envía un trabajo, el usuario especifica a que cuenta se debe
 cargar los recursos consumidos por el trabajo.
\end_layout

\begin_layout Paragraph
Reservas anticipadas
\end_layout

\begin_layout Standard
Las reservas anticipadas permiten que un sitio disponga ciertos recursos
 a un lado para el uso específico de de ciertas aplicaciones durante cierto
 tiempo.
 El acceso a una reserva dada es controlado por un Access Control List (ACL)
 que determina quién puede utilizar los recursos reservados.
 Es importante observar que mientras que un ACL permite que trabajos particulare
s utilicen recursos reservados, no fuerzan al trabajo a utilizar estos recursos.
 Maui procurará utilizar la mejor combinación posible de recursos disponibles
 sean éstos reservados o no.
 Maui puede ser configurado para que ciertos trabajos sean restringidos
 y que funcionen utilizando solamente recursos reservados, aplicando restriccion
es a nivel de trabajo o especificando ciertas restricciones especiales de
 QoS.
 
\end_layout

\begin_layout Paragraph
Quality of Service (QoS)
\end_layout

\begin_layout Standard
Las funciones de QoS permiten otorgar ciertos privilegios especiales a usuarios,
 estos beneficios pueden incluir acceso a recursos adicionales, exclusiones
 de determinadas políticas, acceso a capacidades especiales, y mejoras en
 la priorizacion de trabajos.
\end_layout

\begin_layout Paragraph
Faireshare
\end_layout

\begin_layout Standard
Este componente permite favorecer trabajos en base al uso histórico a corto
 plazo.
 Es posible así ajustar la prioridad de un trabajo dependiendo de la utilización
 porcentual del sistema de usuarios, grupos, o QoS.
 Dada una ventana de tiempo determinado sobre la cual se evalúa la utilización
 de recursos del sistema se determina si esta siendo mantenido un cierto
 balanceo o no.
\end_layout

\begin_layout Subsubsection
Interfaz de programación
\end_layout

\begin_layout Itemize
Interfaz de extensión (Extension Interface)
\end_layout

\begin_deeper
\begin_layout Itemize
Esta interfaz permite que bibliotecas externas sean 'linkeadas' al servidor
 de Maui brindando acceso a todos los datos y objetos utilizados por el
 planificador.
 Además, permite que estas bibliotecas realicen override de las principales
 funciones de Maui.
\end_layout

\end_deeper
\begin_layout Itemize
Interfaz local
\end_layout

\begin_deeper
\begin_layout Itemize
Se trata de una interfaz en C que permite el desarrollo de nuevos algoritmos.
\end_layout

\end_deeper
\begin_layout Subsubsection
Estadísticas
\end_layout

\begin_layout Standard
Maui almacena tres diferentes clases de estadísticas:
\end_layout

\begin_layout Itemize
Estadísticas de tiempo real
\end_layout

\begin_deeper
\begin_layout Itemize
Estas estadísticas son mantenidas en memoria y pueden ser consultadas mediante
 comandos.
 El comando 'showstats' provee información detallada por usuario, por grupo,
 por cuenta o por nodo.
 Además en cualquier momento estas estadísticas pueden resetearse utilizando
 el comando 'resetstats'.
 
\end_layout

\end_deeper
\begin_layout Itemize
Histórico
\end_layout

\begin_deeper
\begin_layout Itemize
Estas estadísticas pueden ser obtenidas para un lapso de tiempo, un tipo
 de trabajo y/o una porción de recursos utilizando el comando 'profiler'.
 Este comando trabaja con la traza de información detallada de un trabajo,
 que es guardada al dar por finalizado un trabajo.
 Estas trazas son almacenadas en el directorio configurado por el parámetro
 STATDIR (por defecto $(MAUIHOMEDIR)/stats) en archivos utilizando el formato
 WWW_MMM_DD_YYYY (p.
 ej.
 Mon_Jul_16_2001), siendo esta fecha la fecha de finalización del trabajo.
 La traza de un trabajo se almacena en texto plano utilizando espacios como
 separadores, por lo que puede ser analizado directamente con cualquier
 editor de texto.
 
\end_layout

\end_deeper
\begin_layout Itemize
Fairshare
\end_layout

\begin_deeper
\begin_layout Itemize
Este tipo de estadísticas son mantenidas sin importar si fairshare se encuentra
 habilitado.
 Al igual que las trazas de los trabajos, estas son almacenadas en archivos
 utilizando texto plano en el directorio configurado por el parámetro STATDIR
 y utilizando el formato FS.<EPOCHTIME> (p.ej., FS.982713600) por cada ventana
 de fairshare.
 Se puede obtener información de estos archivos utilizando el comando 'diagnose
 -f'.
 
\end_layout

\end_deeper
\begin_layout Subsection
Gold
\end_layout

\begin_layout Standard
Gold es un sistema de contaduría open-source desarrollado en PNNL bajo el
 proyecto Scalable Systems Software (SSS) que lleva registro y maneja el
 uso de recursos en clusters de alto desempeño.
 Actúa de la misma forma que un banco en el que son depositados créditos
 en cuentas, estos créditos representan recursos en el sistema.
 A medida que se finalizan trabajos o que son consumidos recursos en el
 sistema se debitan créditos de sus respectivas cuentas.
\end_layout

\begin_layout Standard
Es posible realizar operaciones como depósitos, retiros, transferencias
 o reembolsos sobre las cuentas del sistema, además, provee listados de
 balances a usuarios y administradores.
\end_layout

\begin_layout Subsubsection
Características generales
\end_layout

\begin_layout Paragraph
Reservas
\end_layout

\begin_layout Standard
Previo al inicio de un trabajo se realiza una estimación del total de recursos
 que este consumirá, en base a esta estimación se reservan créditos en la
 cuenta correspondiente.
 Estos créditos 'reservados' se debitan una vez que el trabajo es terminado,
 de esta manera se evita que un proyecto consuma mas recursos de los que
 tiene asignados.
\end_layout

\begin_layout Paragraph
Vencimiento de créditos
\end_layout

\begin_layout Standard
Puede especificarse un lapso de validez a los créditos en el sistema, permitiend
o que se implemente una política de use-it-or-lose-it previniendo el uso
 exhaustivo de créditos acumulados y estableciendo ciclos a un proyecto.
\end_layout

\begin_layout Paragraph
Interfaz web
\end_layout

\begin_layout Standard
Permitiendo acceso remoto a usuarios y administradores.
 
\end_layout

\begin_layout Paragraph
Interfaz de programación
\end_layout

\begin_layout Standard
Existen diferentes formas de integrar Gold al sistema: Perl API, Java API
 o directamente utilizando el protocolo SSSRMAP (basado en XML).
\end_layout

\begin_layout Subsection
Conclusiones
\end_layout

\begin_layout Standard
Torque junto con Maui y Gold satisfacen los requerimientos planteados para
 el proyecto.
 Su consumo de recursos del cluster es relativamente bajo, se adapta muy
 bien al manejo de clusters pequeños y posee un manejo eficiente de trabajos
 paralelos (sobre todo si estos son homogéneos).
 
\end_layout

\begin_layout Standard
Pero existen ciertos aspectos en los que Torque no se desempeña de la mejor
 manera.
 Si bien se encuentra integrado el soporte para bibliotecas tipo MPI, no
 existe un correcto soporte para PVM.
 Además existen ciertas carencias en sus funcionalidades de Resource Management;
 p.
 ej.
 no es capaz de realizar CPU Harvesting o migración de procesos.
 
\end_layout

\begin_layout Standard
Si bien existe un buen soporte por parte de la comunidad de usuarios de
 Torque y Maui por medio de listas de correo, la documentación disponible
 en el sitio web se encuentra incompleta en algunos aspectos (p.
 ej.
 PVM, interfaces de programación, etc.).
 Como es de esperar esta documentación se encuentra mas completa para Moab
 (la versión comercial de Maui), y si bien son productos diferentes son
 similares en muchos aspectos.
\end_layout

\begin_layout Bibliography

\bibitem [1]{key-1}
B.
 Radic, E.
 Imamagic: Benchmarking the Performance of JMS on Computer Clusters, CARNet
 Users' Conference, 28.
 9.
 2004.
\end_layout

\begin_layout Bibliography

\bibitem [2]{key-2}
E.
 Imamagic, B.
 Radic, D.
 Dobrenic: Job Management Systems Analysis, CARNet Users' Conference, 28.
 9.
 2004.
\end_layout

\begin_layout Bibliography

\bibitem [3]{key-3}
Maui Cluster Scheduler, Cluster Resources.
 http://www.clusterresources.com/products/maui/
\end_layout

\begin_layout Bibliography

\bibitem [4]{key-4}
Torque Resource Manager, Cluster Resources.
 http://www.clusterresources.com/products/torque/
\end_layout

\begin_layout Bibliography

\bibitem [5]{key-5}
William Gropp, Ewing Lusk and Thomas Sterling.
 Beowulf Cluster Computing with Linux, Second Edition.
 The MIT press, 2003 ISBN:0262692929 
\end_layout

\begin_layout Standard

\end_layout

\end_body
\end_document
